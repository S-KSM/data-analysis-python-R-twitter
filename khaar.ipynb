{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import collections\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "`symt_list` shows the symptoms that are used to identify allergy related tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_list = []\n",
    "tweet_dict = {}\n",
    "dfs = []\n",
    "symt_list = [\"sneeze\", \"allergies\", \"allergy\",\"runny nose\",\"rash\",\"itchy\",\"itch\"]\n",
    "path = \"./data/*.txt\"\n",
    "path_AQ = \"./data/*.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets!\n",
    "\n",
    "Reads the Tweets files from both test and training files, line by line. If there is any of our keywords in the tweet, it will add it to our `tweet_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for file in glob.glob(path):\n",
    "    with open(file,'r',encoding=\"ISO-8859-1\") as f:\n",
    "        for line in f.readlines():\n",
    "            #print(line.split)\n",
    "            for word in symt_list:\n",
    "                if word in line.lower().split():\n",
    "                    tweet_list.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air pollution\n",
    "Reads all the different states files. and uses three columns (date, PM2.5 concentration, and the states name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for AQ_states in glob.glob(path_AQ):\n",
    "    df = pd.read_csv(AQ_states,sep = \",\",usecols=[0,3,13])\n",
    "    dfs.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning tweets\n",
    "\n",
    "Selects the tweets that are from 2009, since this is the only full year in the data set.\n",
    "\n",
    "Next. It counts to see how many tweets are per each date and saves the number in the `tweet_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in tweet_list:\n",
    "    tweet_temp = tweet.split(\"\\t\").pop(-1).split()[0]\n",
    "    if re.match(r'20[0-1][9]',tweet_temp):\n",
    "        if tweet_temp in tweet_dict:\n",
    "            tweet_dict[tweet_temp] +=1\n",
    "        else:\n",
    "            tweet_dict[tweet_temp] = 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frame:\n",
    "\n",
    "Here, it makes a `pandas` data frame from the `tweet_dict` so that we can save them later into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tweets = pd.DataFrame.from_records([tweet_dict]).T.reset_index()\n",
    "df_tweets.columns = [\"date\",\"numTweets\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatanates and aggregates all the states air-pollution data into the `final_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writes the dataframes into a csv file that will be used by `R` later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(\"./cleandata/PM2.csv\")\n",
    "df_tweets.to_csv(\"./cleandata/tweets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
